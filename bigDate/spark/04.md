[TOC]

![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190508213424.png)

![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190512175358.png)

![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190512175826.png)


# 1. 构建DAG（有向无环图） （Driver端） 
1. 描述了多个RDD转换过程，任务执行时，可以按照DAG的描述来执行真正的计算
2. DAG是有边界的
    1. 开始： 通过SparkContext创建RDD
    2. 结束：触发Action，调用run job
3. 一个RDD只是描述了数据计算中的一个环节，而DAG是由多个RDD组成，DAG描述了计算过程中的所有环节
4. 一个Spark Application中有1到多个DAG
5. 一个DAG中可能产生多个不同类型和不同功能的Task

# 2. DAGScheduler（DAG调度）（Driver端）
`stage 阶段`  
将一个DAG切分成一到多个Stage，DAGScheduler切分的依据是Shuffle（宽依赖，将多台机器上具有相同属性的数据聚合到一台机器上，`父RDD一个分区中的数据如果给了子RDD的多个分区这就是shuffle` , `shuffle会有网络传输 ，但是与网络传输不一定的shuffle`）   
1. 为什么要切分Stage
    1. 一个复杂的业务逻辑如果有shuffle，那么意味着需要执行后面的结果就需要限制性前面的阶段。下一个阶段的计算依赖于上一个阶段的数据
    2. 在同一个Stage中，会有多个算子，可以合并在一起，称为pipeline（流水线）
2. 什么是宽依赖，什么是窄依赖
    1. 宽依赖：父RDD中一个分区中数据，如果给了子RDD的多个分区，那么就是宽依赖（即使存在可能）
    2. 窄依赖：先分组，然后join，不管你却没有改变生成的RDD分区和数量


# 3. TaskScheduler调度Task  （Driver端）
1. 先提交前面是Stage，执行完后再提交后面是Stage    
2. 一个Stage会产生很多业务逻辑相同的Task    
3. 然后以TaskSet的形式传递给TaskScheduler 
4. TaskScheduler 将Task序列化
5.  根据情况发送给Executor


# 4. 执行Task（Excutor端）
1. Executor 接受到Task
2. 将Task反序列化   
3. 将Task用一个实现了Runna接口的实现类包装起来
4. 将此包装类放入线程池中
5. 包装类的run方法会被执行，从而调用Task计算逻辑


![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190512223639.png)

```
1.SparkContext哪一端生成的？
	Driver端

2.DAG是在哪一端被构建的？
    Driver端
    
3.RDD是在哪一端生成的？
	Driver端

4.广播变量是在哪一端调用的方法进行广播的？
	Driver端

5.要广播的数据应该在哪一端先创建好再广播呢？ 
	Driver端

6.调用RDD的算子（Transformation和Action）是在哪一端调用的
	Driver端
	
7.RDD在调用Transformation和Action时需要传入一个函数，函数是在哪一端声明和传入的?
	Driver端

6.RDD在调用Transformation和Action时需要传入函数，请问传入的函数是在哪一端执行了函数的业务逻辑？
	Executor中的Task执行的

7.自定义的分区器这个类是在哪一端实例化的？
	Driver端

8.分区器中的getParitition方法在哪一端调用的呢？
	Executor中的Task中调用的

9.Task是在哪一端生成的呢？ 
	Driver端

10.DAG是在哪一端构建好的并被切分成一到多个State的
	Driver端

11.DAG是哪个类完成的切分Stage的功能？
	DAGScheduler
	
12.DAGScheduler将切分好的Stage以什么样的形式给TaskScheduler
	TaskSet
	
	
RDD是spark中的一个最基本的抽象，代表着一个不可变、可分区、可以并行计算的分布式数据集
RDD有5个特点
	1.一系列分区
	2.会有一个函数作用在每个切片上
	3.RDD和RDD之间存在依赖关系
	4（可选）如果是RDD中装的是KV类型的，那么Shuffle时会有一个分区器。默认是HashPartitioner
	5（可选）如果只从HDFS中读取数据，会感知数据则位置，将Executor启动在数据所在的机器上

Spark的设计就是基于这个抽象的数据集（RDD），你操作RDD这个抽象的数据集，就像操作一个本地集合一样，Spark包底层的细节都隐藏起来的（任务调度、Task执行，任务失败重试等待），开发者使用起来更加方便简洁

操作RDD，其实是对每个分区进行操作，分区会生成Task，Task会调度Executor上执行相关的计算逻辑，进而对数据进操作
```