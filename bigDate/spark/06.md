[TOC]
# 1. join
## 1.1 概况
1. spark1.x中 有三种join
2. spark2.x中 只有两种join了

## 1.2 SparkSQL的三种Join实现   
### 1.2.1 Broadcast Join
- 将小表全部广播到每个节点上面去
- 实际上不会在每台Executor上存所有的数据，会类似于BT下载的方式每个人持有一部分
![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190515195906.png)
使用的条件: 
- 被广播的表需要小于`spark.sql.autoBroadcastJoinThreshold`配置的值（默认为10MB）


### 1.2.2 Shuffle Hash Join（默认）
![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190515200641.png)
- 将大量数据划分为n份相对小的数据进行计算
- 通过Join的条件key相同，将key通过Hash计算，实现将相同的key分发到相同的机器上
- 一定程度上减少了driver广播一侧的压力，也减少了Executor端因为广播整张表而消耗的内存；

### 1.2.3 Sort Merge Join
-  Broadcast Join和Shuffle Hash Join 适用于一定大小的表，当两个表都非常大时候，就不合适了。第一种的将表的一侧全部加载到内存中，第二种是取join key值相等的记录进行连接
-  Sort Merge Join，这种方式是不用将一侧的数据全部架子啊进hash join，但是需要在join前对数据进行排序    
![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190515202925.png)
- 两个序列都是有序的，从头遍历，碰到key相同的就输出；如果不同，左边小就继续取左边，反之取右边。
- 无论分区有多大，Sort Merge Join都不用把某一侧的数据全部加载到内存中，而是即用即取即丢，从而大大提升了大数据量下sql join的稳定性。
- 如何使用修改 `spark.sql.autoBroadcastJoinThreshold` 的值为-1即可

# 2. 默认是BroadcastHashJoin
# 1. SparkSQL版本ip匹配
使用join来一次匹配一次join是个瓶颈
```
public class IpLocationSQL {
    public static void main(String[] args) {
        SparkSession session = SparkSession.builder()
                .appName("SparkSession")
                .master("local[*]")
                .getOrCreate();

        //读取规则
        JavaRDD<Ruler> rulers = session.read()
                .textFile("H:\\javaCode\\ideaCode\\Android\\SparkDemo\\file\\ip.txt")
                .toJavaRDD()
                .map(line -> {
                    String[] lineArr = line.split("[|]");
                    Long ipStart = Long.parseLong(lineArr[2]);
                    Long ipEnd = Long.parseLong(lineArr[3]);
                    return new Ruler(ipStart, ipEnd, lineArr[6] + "_" + lineArr[7]);
                });

        //读取数据
        JavaRDD<Logs> logs = session.read()
                .textFile("H:\\javaCode\\ideaCode\\Android\\SparkDemo\\file\\access.log")
                .toJavaRDD().map(line -> {
                    String ip = line.split("[|]")[1];
                    return new Logs(IpConversion.ipConversion(ip));
                });

        //创建DataFrame
        Dataset<Row> rulersData = session.createDataFrame(rulers, Ruler.class);

        Dataset<Row> logsData = session.createDataFrame(logs,Logs.class);

        //创建视图
        rulersData.createOrReplaceTempView("rulers");
        logsData.createOrReplaceTempView("logs");

        //创建sql
        Dataset<Row> result = session.sql("SELECT city,count(*) sum " +
                "from rulers join logs on(ipStart<=ip and ipEnd>ip) group by city order by sum desc,city");

        result.show();

        session.stop();
    }

    public static class Logs{
        private Long ip;

        public Long getIp() {
            return ip;
        }

        public void setIp(Long ip) {
            this.ip = ip;
        }

        public Logs(Long ip) {
            this.ip = ip;
        }
    }
    public static class Ruler{
        private Long ipStart;
        private Long ipEnd;
        private String city;

        public Ruler(Long ipStart, Long ipEnd, String city) {
            this.ipStart = ipStart;
            this.ipEnd = ipEnd;
            this.city = city;
        }

        public Long getIpStart() {
            return ipStart;
        }

        public void setIpStart(Long ipStart) {
            this.ipStart = ipStart;
        }

        public Long getIpEnd() {
            return ipEnd;
        }

        public void setIpEnd(Long ipEnd) {
            this.ipEnd = ipEnd;
        }

        public String getCity() {
            return city;
        }

        public void setCity(String city) {
            this.city = city;
        }
    }
}
```