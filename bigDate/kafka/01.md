[TOC]

# 1. 概念
1. Boreder：安装Kafka服务器的那几台集群就是一个Briker
2. Producer :消息生产者，负责将数据写入Broker中（pull）
3. Consumer:消息的消费者，负责从Kafka中读取数据（pull）,老版本的消费需要依赖ZK，新版本不需要
4. Topic：主题，相当于是数据的一个分类，不同topic存放不同的数据  
5. Consumer Group：消费者组，一个Topic可以有多个消费之同时消费，多个消费之如果在同一个消费者组中，那么他们不能重复消费数据
![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190519040506.png)

# 2. 安装
## 2.1 0.8x安装
1. 上传文件 
2. 解压
3. 修改配置文件`config/server.properties`
    1. `broker.id=0` //全局唯一
    2. `host.name=vm01` //监听地址
    3. `log.dirs=/home/chenpeng/apps/bigdate/file/kafka` //存储的位置 文件 非日志
    4. `log.retention.hours=168`  //多久删除
    5. `zookeeper.connect=vm01:2181,vm02:2181,vm03:2181`   //配置zk
4. 拷贝到集群的其他位置
5. 修改`broker.id` 和 `host.name`
6. 启动 
    ```
    bin/kafka-server-start.sh -daemon config/server.properties
    ```

## 2.2  0.10x安装
配置文件    
1. `broker.id=0` //全局唯一
2. `delete.topic.enable=true` //可以手动删除
3. 设置监听 
    `listeners=PLAINTEXT://vm01:9092`
    `advertised.listeners=PLAINTEXT://vm01:9092`
4. `log.dirs=/home/chenpeng/apps/bigdate/file/kafka` //存储的位置 文件 非日志
5. `zookeeper.connect=vm01:2181,vm02:2181,vm03:2181`   //配置zk


# 3. 使用
    #查看topic信息
	/home/chenpeng/apps/bigdate/kafka/kafka_2.11-0.8.2.2/bin/kafka-topics.sh --list --zookeeper vm01:2181,vm02:2181,vm03:2181
	
    /home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-topics.sh --list --zookeeper vm01:2181,vm02:2181,vm03:2181
    
	#创建topic
	/home/chenpeng/apps/bigdate/kafka/kafka_2.11-0.8.2.2/bin/kafka-topics.sh --create --zookeeper vm01:2181,vm02:2181,vm03:2181 --replication-factor 3 --partitions 3 --topic chen
    
    /home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-topics.sh --create --zookeeper vm01:2181,vm02:2181,vm03:2181 --replication-factor 3 --partitions 3 --topic chen
    
    # 查看细节
    /home/chenpeng/apps/bigdate/kafka/kafka_2.11-0.8.2.2/bin/kafka-topics.sh --describe --zookeeper vm01:2181,vm02:2181,vm03:2181 --topic user

	#往Kafka的topic中写入数据(命令行的生成者)
	/home/chenpeng/apps/bigdate/kafka/kafka_2.11-0.8.2.2/bin/kafka-console-producer.sh --broker-list vm01:9092,vm02:9092,vm03:9092 --topic chen
	
    /home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-console-producer.sh --broker-list vm01:9092,vm02:9092,vm03:9092 --topic chen
    
    /home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-console-producer.sh --broker-list vm01:9092,vm02:9092,vm03:9092 --topic chen
    
	#启动消费者
	/home/chenpeng/apps/bigdate/kafka/kafka_2.11-0.8.2.2/bin/kafka-console-consumer.sh --zookeeper vm01:2181,vm02:2181,vm03:2181 --topic chen --from-beginning
	
	/home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-console-consumer.sh --zookeeper vm01:2181,vm02:2181,vm03:2181 --topic chen --from-beginning
	
	/home/chenpeng/apps/bigdate/kafka/kafka_2.12-2.2.0/bin/kafka-console-consumer.sh --bootstrap-server vm01:9092,vm02:9092,vm03:9092 --topic track --from-beginning
## 3.1 kafka2.x
```
第3步：创建主题
让我们创建一个名为“test”的主题，它只包含一个分区，只有一个副本：

1
> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
如果我们运行list topic命令，我们现在可以看到该主题：

1
2
> bin/kafka-topics.sh --list --bootstrap-server localhost:9092
test
或者，您可以将代理配置为在发布不存在的主题时自动创建主题，而不是手动创建主题。

第4步：发送一些消息
Kafka附带一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。默认情况下，每行将作为单独的消息发送。

运行生产者，然后在控制台中键入一些消息以发送到服务器。

1
2
3
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
第5步：启动消费者
Kafka还有一个命令行使用者，它会将消息转储到标准输出。

1
2
3
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
This is a message
This is another message
如果您在不同的终端中运行上述每个命令，那么您现在应该能够在生产者终端中键入消息并看到它们出现在消费者终端中。

所有命令行工具都有其他选项; 运行不带参数的命令将显示更详细地记录它们的使用信息。
```
	

# 4. idea demo
1. 生产者
```
package com.cp.demo1;

import java.util.Properties;

import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;


/**
 * @author chenPeng
 * @version 1.0.0
 * @ClassName ProduceDemo.java
 * @Description TODO
 * @createTime 2019年05月19日 19:31:00
 */
public class ProduceDemo {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("metadata.broker.list", "vm01:9092,vm02:9092,vm03:9092");
        props.put("serializer.class", "kafka.serializer.StringEncoder");
        ProducerConfig config = new ProducerConfig(props);
        Producer<String, String> producer = new Producer<>(config);
        for (int i = 90000; i <= 91000; i++){
            producer.send(
                            new KeyedMessage<String, String>("chenpeng", "chenpeng—test-msg" + i));
        }
    }
}

```

2. 消费者
```
package com.cp.demo1;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.message.MessageAndMetadata;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

/**
 * @author chenPeng
 * @version 1.0.0
 * @ClassName ConsumerDemo.java
 * @Description TODO
 * @createTime 2019年05月19日 19:31:00
 */
public class ConsumerDemo {
    private static final String topic = "chenpeng";
    private static final Integer threads = 2;

    public static void main(String[] args) {

        Properties props = new Properties();
        props.put("zookeeper.connect", "vm01:2181,vm02:2181,vm03:2181");
        props.put("group.id", "vvvv1");
        //smallest重最开始消费,largest代表重消费者启动后产生的数据才消费
        //--from-beginning
        props.put("auto.offset.reset", "smallest");

        ConsumerConfig config = new ConsumerConfig(props);
        ConsumerConnector consumer = Consumer.createJavaConsumerConnector(config);
        Map<String, Integer> topicCountMap = new HashMap<>(16);
        topicCountMap.put(topic, threads);
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);
        List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(topic);

        for(final KafkaStream<byte[], byte[]> kafkaStream : streams){
            new Thread(new Runnable() {
                @Override
                public void run() {
                    for(MessageAndMetadata<byte[], byte[]> mm : kafkaStream){
                        String msg = new String(mm.message());
                        System.out.println(msg);
                    }
                }
            }).start();
        }
    }
}

```


# 5. kafka分区
![](https://raw.githubusercontent.com/shutter-cp/imgBed/master/img/20190519220042.png)